Je to velmi ambici√≥zn√≠ a zaj√≠mav√Ω po≈æadavek! P≈ôevod konzolov√© aplikace na plnohodnotn√© webov√© rozhran√≠ s podporou hlasov√©ho vstupu/v√Ωstupu, zpracov√°n√≠ obr√°zk≈Ø, ≈æiv√©ho re≈æimu a integrace s prohl√≠≈æeƒçem vy≈æaduje mnohem komplexnƒõj≈°√≠ architekturu ne≈æ pouh√Ω Python skript bƒõ≈æ√≠c√≠ v termin√°lu.

Nelze vytvo≈ôit kompletn√≠ webovou aplikaci (s HTML, CSS, JavaScriptem a real-time audio/video zpracov√°n√≠m) v r√°mci jedn√© v√Ωstupn√≠ zpr√°vy, ale mohu poskytnout **konceptu√°ln√≠ Python Flask aplikaci**, kter√° bude slou≈æit jako **backend** pro takov√© rozhran√≠. Vysvƒõtl√≠m, jak by jednotliv√© ƒç√°sti fungovaly a jak√© n√°stroje a slu≈æby byste pot≈ôeboval.

**Kl√≠ƒçov√© komponenty a principy:**

1.  **Frontend (UI):**
    *   **HTML/CSS/JavaScript:** Toto je ƒç√°st, kterou by u≈æivatel vidƒõl a se kterou by interagoval v prohl√≠≈æeƒçi (nap≈ô. Chromium). Zde by se implementovala tlaƒç√≠tka, textov√© pole, p≈ôep√≠naƒçe, zobrazen√≠ textu, p≈ôehr√°v√°n√≠ zvuku.
    *   **JavaScript API:** Pro p≈ô√≠stup k mikrofonu (`Web Speech API`), p≈ôehr√°v√°n√≠ zvuku (`Web Audio API`), a potenci√°lnƒõ pro nahr√°v√°n√≠ obr√°zk≈Ø.
    *   **WebSockets:** Pro "≈æiv√Ω re≈æim" a plynulou, obousmƒõrnou komunikaci mezi prohl√≠≈æeƒçem a Python backendem.

2.  **Backend (Python Flask):**
    *   **Flask:** Lehk√Ω webov√Ω framework pro Python, kter√Ω bude p≈ôij√≠mat po≈æadavky z prohl√≠≈æeƒçe a pos√≠lat odpovƒõdi.
    *   **Integrace s Gemini API:** St√°le pou≈æ√≠v√°me Gemini pro inteligenci AI.
    *   **Text-to-Speech (TTS) slu≈æba:** Pro p≈ôevod textov√Ωch odpovƒõd√≠ AI na ≈ôeƒç (nap≈ô. Google Cloud Text-to-Speech API).
    *   **Speech-to-Text (STT) slu≈æba:** Pro p≈ôevod hlasov√©ho vstupu u≈æivatele na text (nap≈ô. Google Cloud Speech-to-Text API).
    *   **Image Analysis/Vision API:** Pro zpracov√°n√≠ obr√°zk≈Ø (nap≈ô. Google Cloud Vision API nebo Gemini Vision model).
    *   **Browser Automation:** Pro p≈ô√≠mou podporu vyhled√°v√°n√≠ a anal√Ωzy na webu (nap≈ô. Selenium nebo Playwright s headless Chromium).

**Nyn√≠ v√°m p≈ôedstav√≠m strukturu a k√≥d pro Flask backend.** Pamatujte, ≈æe toto je **z√°kladn√≠ kostra**, kter√° bude vy≈æadovat podrobnou implementaci frontendu a konfiguraci extern√≠ch API slu≈æeb (Google Cloud Platform, atd.).

---

### **P≈ô√≠prava projektu (manu√°ln√≠ kroky p≈ôed spu≈°tƒõn√≠m):**

1.  **Vytvo≈ôte adres√°≈ôovou strukturu:**
    ```
    mkdir ai_dev_manager_web
    cd ai_dev_manager_web
    mkdir project_root # pro AI development
    mkdir project_root/src
    mkdir project_root/tests
    mkdir logs         # pro AI logy
    mkdir archived_states
    mkdir static       # pro frontend soubory (CSS, JS)
    mkdir templates    # pro HTML soubory
    ```
2.  **Vytvo≈ôte soubor `development_plan.txt` v `ai_dev_manager_web` (stejn√Ω jako d≈ô√≠ve).**
3.  **Nastavte promƒõnnou prost≈ôed√≠ `GOOGLE_API_KEY` (a p≈ô√≠padnƒõ dal≈°√≠ API kl√≠ƒçe pro STT/TTS/Vision API, pokud je budete pou≈æ√≠vat):**
    ```bash
    export GOOGLE_API_KEY='V√Å≈†_API_KL√çƒå_ZDE'
    # Pokud pou≈æ√≠v√°te Google Cloud API pro STT/TTS/Vision, budete pot≈ôebovat i JSON kl√≠ƒç √∫ƒçtu slu≈æby
    # export GOOGLE_APPLICATION_CREDENTIALS="/cesta/k/vasemu/service_account_key.json"
    ```
4.  **Nainstalujte pot≈ôebn√© knihovny:**
    ```bash
    pip install google-generative-ai Flask Flask-SocketIO python-socketio[client] python-dotenv google-cloud-texttospeech google-cloud-speech google-cloud-vision selenium webdriver_manager difflib
    ```
    *   `Flask-SocketIO`: Pro WebSockets (nutn√© pro ≈æiv√Ω re≈æim a audio streamov√°n√≠).
    *   `google-cloud-texttospeech`, `google-cloud-speech`, `google-cloud-vision`: Ofici√°ln√≠ knihovny Google Cloud pro pr√°ci s TTS/STT/Vision.
    *   `selenium`, `webdriver_manager`: Pro automatizaci prohl√≠≈æeƒçe.

---

### **Python Backend K√≥d (`ai_dev_manager_web/app.py`):**

```python
import google.generativeai as genai
import os
import io
import contextlib
import traceback
import re
import datetime
import shutil
import zipfile
import difflib
from flask import Flask, render_template, request, jsonify, session
from flask_socketio import SocketIO, emit
from google.cloud import texttospeech_v1beta as texttospeech
from google.cloud import speech_v1p1beta1 as speech
from google.cloud import vision
# from selenium import webdriver # Pro Selenium (vy≈æaduje sta≈æen√Ω webdriver)
# from selenium.webdriver.chrome.service import Service as ChromeService
# from webdriver_manager.chrome import ChromeDriverManager # Automatick√° spr√°va webdriveru

# --- Konfigurace pro Gemini API ---
try:
    genai.configure(api_key=os.environ["GOOGLE_API_KEY"])
except KeyError:
    print("Chyba: Promƒõnn√° prost≈ôed√≠ 'GOOGLE_API_KEY' nen√≠ nastavena.")
    print("Pros√≠m, nastavte ji pomoc√≠: export GOOGLE_API_KEY='v√°≈°_api_kl√≠ƒç'")
    exit()

# Inicializace model≈Ø Gemini
code_model = genai.GenerativeModel('gemini-2.5-flash-lite')
# Pro obr√°zky byste mohli pou≈æ√≠t model s podporou multimodality, nap≈ô. 'gemini-pro-vision'
# vision_model = genai.GenerativeModel('gemini-pro-vision') # Pokud ho budete vyu≈æ√≠vat

# --- Cesty k adres√°≈ô≈Øm projektu ---
PROJECT_ROOT = 'project_root'
LOGS_DIR = 'logs'
ARCHIVE_DIR = 'archived_states'
DEVELOPMENT_PLAN_FILE = 'development_plan.txt'
CODE_CHANGES_LOG = os.path.join(LOGS_DIR, 'code_changes.log')

# Zajistƒõte, ≈æe adres√°≈ôe existuj√≠
os.makedirs(PROJECT_ROOT, exist_ok=True)
os.makedirs(os.path.join(PROJECT_ROOT, 'src'), exist_ok=True)
os.makedirs(os.path.join(PROJECT_ROOT, 'tests'), exist_ok=True)
os.makedirs(LOGS_DIR, exist_ok=True)
os.makedirs(ARCHIVE_DIR, exist_ok=True)

# --- Flask a SocketIO Setup ---
app = Flask(__name__)
app.config['SECRET_KEY'] = 'your_secret_key_for_flask_sessions' # Zmƒõ≈àte na bezpeƒçn√Ω kl√≠ƒç!
socketio = SocketIO(app, cors_allowed_origins="*") # Povolit CORS pro jednoduchost developmentu

# --- Inicializace Google Cloud Clients (pokud budete pou≈æ√≠vat) ---
# Ujistƒõte se, ≈æe m√°te nastavenou promƒõnnou prost≈ôed√≠ GOOGLE_APPLICATION_CREDENTIALS
# nebo autentifikaci jin√Ωm zp≈Øsobem.
tts_client = texttospeech.TextToSpeechClient()
stt_client = speech.SpeechClient()
vision_client = vision.ImageAnnotatorClient()

# Glob√°ln√≠ promƒõnn√© pro stav (pro demonstraƒçn√≠ √∫ƒçely, v produkci pou≈æijte session/datab√°zi)
# Tady budeme dr≈æet chat historii pro ka≈æd√©ho u≈æivatele (pokud by bylo v√≠ce u≈æivatel≈Ø)
user_chats = {}
live_mode_enabled = False # Glob√°ln√≠ pro demo, v produkci per-session
tts_output_enabled = False # Glob√°ln√≠ pro demo, v produkci per-session

# --- Pomocn√© N√°stroje pro AI Program√°tora (Refaktorov√°no pro Flask) ---
# Nƒõkter√© funkce z≈Øst√°vaj√≠ stejn√©, nƒõkter√© budou m√≠t p≈ôid√°ny logov√°n√≠ a emitov√°n√≠ p≈ôes SocketIO

def _read_file_content(filepath: str) -> str:
    # ... (stejn√© jako p≈ôedt√≠m)
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        return f"Chyba: Soubor '{filepath}' nebyl nalezen."
    except Exception as e:
        return f"Chyba p≈ôi ƒçten√≠ souboru '{filepath}': {e}"

def read_file_tool(filepath: str) -> str:
    # ... (stejn√© jako p≈ôedt√≠m)
    absolute_path = os.path.join(PROJECT_ROOT, filepath)
    result = _read_file_content(absolute_path)
    log_activity_tool("File Access", "READ_FILE", f"Soubor p≈ôeƒçten: {filepath}. V√Ωsledek: {result[:100]}...") # Zkr√°cen√Ω log
    return result

def list_directory_tool(path: str) -> str:
    # ... (stejn√© jako p≈ôedt√≠m)
    absolute_path = os.path.join(PROJECT_ROOT, path)
    try:
        entries = os.listdir(absolute_path)
        dirs = [e for e in entries if os.path.isdir(os.path.join(absolute_path, e))]
        files = [e for e in entries if os.path.isfile(os.path.join(absolute_path, e))]
        
        result = f"Obsah adres√°≈ôe '{path}':\n"
        if dirs: result += "Adres√°≈ôe: " + ", ".join(dirs) + "\n"
        if files: result += "Soubory: " + ", ".join(files) + "\n"
        if not dirs and not files: result += "Adres√°≈ô je pr√°zdn√Ω.\n"
        
        log_activity_tool("File Access", "LIST_DIR", f"Adres√°≈ô vyps√°n: {path}")
        return result
    except FileNotFoundError:
        log_activity_tool("Error", "LIST_DIR", f"Adres√°≈ô nenalezen: {path}")
        return f"Chyba: Adres√°≈ô '{path}' nebyl nalezen."
    except Exception as e:
        log_activity_tool("Error", "LIST_DIR", f"Chyba p≈ôi v√Ωpisu adres√°≈ôe '{path}': {e}")
        return f"Chyba p≈ôi v√Ωpisu adres√°≈ôe '{path}': {e}"

def write_code_to_file_tool(filename: str, code_content: str) -> str:
    # ... (stejn√© jako p≈ôedt√≠m)
    absolute_path = os.path.join(PROJECT_ROOT, filename)
    old_content = ""
    if os.path.exists(absolute_path): old_content = _read_file_content(absolute_path)

    try:
        os.makedirs(os.path.dirname(absolute_path) or '.', exist_ok=True)
        with open(absolute_path, 'w', encoding='utf-8') as f: f.write(code_content)
        
        log_code_change(filename, old_content, code_content)
        log_activity_tool("Code Change", "WRITE_CODE", f"K√≥d zaps√°n do: {filename}")
        return f"K√≥d byl √∫spƒõ≈°nƒõ ulo≈æen do souboru {filename}."
    except Exception as e:
        log_activity_tool("Error", "WRITE_CODE", f"Chyba p≈ôi z√°pisu k√≥du do '{filename}': {e}")
        return f"Chyba p≈ôi ukl√°d√°n√≠ k√≥du do {filename}: {e}"

def test_python_code_tool(filename: str) -> str:
    # ... (stejn√© jako p≈ôedt√≠m)
    absolute_path = os.path.join(PROJECT_ROOT, filename)
    if not os.path.exists(absolute_path):
        log_activity_tool("Error", "TEST_CODE", f"Soubor nenalezen pro testov√°n√≠: {filename}")
        return f"Chyba: Soubor '{filename}' nebyl nalezen pro testov√°n√≠."

    output_capture = io.StringIO()
    try:
        with contextlib.redirect_stdout(output_capture), contextlib.redirect_stderr(output_capture):
            with open(absolute_path, 'r', encoding='utf-8') as f: code_to_execute = f.read()
            global_scope = {'__name__': '__main__', '__file__': absolute_path}
            local_scope = {}
            exec(code_to_execute, global_scope, local_scope)
        
        result = output_capture.getvalue()
        log_activity_tool("Code Execution", "TEST_CODE", f"Test souboru {filename} - V√Ωstup:\n{result}")
        return f"Spu≈°tƒõn√≠ √∫spƒõ≈°n√©.\nV√Ωstup:\n{result}"
    except Exception as e:
        error_output = output_capture.getvalue()
        full_traceback = traceback.format_exc()
        log_activity_tool("Error", "TEST_CODE", f"Test souboru {filename} - Selhalo:\n{full_traceback}\nV√Ωstup/Chyba:\n{error_output}")
        return f"Spu≈°tƒõn√≠ selhalo.\nChyba:\n{full_traceback}\nV√Ωstup/Chyba zachycen√© p≈ôed p√°dem:\n{error_output}"

def generate_test_boilerplate_tool(target_filename: str, function_names: str) -> str:
    # ... (stejn√© jako p≈ôedt√≠m)
    test_code_template = f"""
import unittest
import os
import sys

# P≈ôidejte project_root/src do cesty, aby bylo mo≈æn√© importovat hlavn√≠ soubory
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'src')))

import {os.path.splitext(target_filename)[0].replace('/', '.')} # Importuje nap≈ô. src.main

class Test{os.path.splitext(target_filename)[0].replace('/', '_').title()}(unittest.TestCase):
"""
    functions_list = [f.strip() for f in function_names.split(',')]
    
    for func_name in functions_list:
        if func_name:
            test_code_template += f"""
    def test_{func_name}(self):
        # TODO: Implementujte testovac√≠ logiku pro funkci '{func_name}'
        # P≈ô√≠klad:
        # result = {os.path.splitext(target_filename)[0].replace('/', '.')}.{func_name}("TestValue")
        # self.assertEqual(result, "ExpectedValue")
        self.fail("Test pro {func_name} je≈°tƒõ nebyl implementov√°n.")

"""
    test_code_template += "\nif __name__ == '__main__':\n    unittest.main()\n"
    
    log_activity_tool("Test Generation", "GENERATE_TEST_BOILERPLATE", f"Generov√°n test boilerplate pro {target_filename} funkce: {function_names}")
    return test_code_template

def log_activity_tool(category: str, action: str, details: str) -> str:
    # ... (stejn√© jako p≈ôedt√≠m)
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_filename = os.path.join(LOGS_DIR, f"activity_{datetime.datetime.now().strftime('%Y-%m-%d')}.log")
    log_entry = f"[{timestamp}] [{category}] [{action}] {details}\n"
    try:
        with open(log_filename, 'a', encoding='utf-8') as f: f.write(log_entry)
        return f"Aktivita zaznamen√°na do {log_filename}."
    except Exception as e: return f"Chyba p≈ôi z√°znamu aktivity: {e}"

def log_code_change(filename: str, old_content: str, new_content: str):
    # ... (stejn√© jako p≈ôedt√≠m)
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    diff = list(difflib.unified_diff(
        old_content.splitlines(keepends=True),
        new_content.splitlines(keepends=True),
        fromfile=f'a/{filename}',
        tofile=f'b/{filename}',
        lineterm=''
    ))
    with open(CODE_CHANGES_LOG, 'a', encoding='utf-8') as f:
        f.write(f"\n--- Code Change: {filename} at {timestamp} ---\n")
        if diff: f.writelines(diff)
        else: f.write("≈Ω√°dn√© podstatn√© zmƒõny (soubor vytvo≈ôen nebo obsah beze zmƒõny).\n")
        f.write("-------------------------------------------\n")

def generate_report_tool(report_title: str) -> str:
    # ... (stejn√© jako p≈ôedt√≠m)
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    report_filename = os.path.join(LOGS_DIR, f"report_{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.md")
    report_content = f"# {report_title} - Zpr√°va o v√Ωvoji\n\n"
    report_content += f"Datum a ƒças generov√°n√≠: {timestamp}\n\n"
    report_content += "## Souhrn aktivit\n"
    try:
        all_activities = []
        for log_file in os.listdir(LOGS_DIR):
            if log_file.startswith("activity_") and log_file.endswith(".log"):
                all_activities.extend(_read_file_content(os.path.join(LOGS_DIR, log_file)).splitlines())
        activity_counts = {}
        for activity in all_activities:
            match = re.search(r'\[(.*?)\] \[(.*?)\] \[(.*?)\]', activity)
            if match:
                category, action = match.group(2), match.group(3)
                key = f"{category} - {action}"
                activity_counts[key] = activity_counts.get(key, 0) + 1
        for key, count in activity_counts.items(): report_content += f"- {key}: {count}x\n"
        report_content += "\n## Zmƒõny v k√≥du (souhrn z code_changes.log)\n"
        if os.path.exists(CODE_CHANGES_LOG): report_content += "```diff\n" + _read_file_content(CODE_CHANGES_LOG) + "\n```\n"
        else: report_content += "≈Ω√°dn√© zaznamenan√© zmƒõny k√≥du.\n"
        with open(report_filename, 'w', encoding='utf-8') as f: f.write(report_content)
        log_activity_tool("Reporting", "GENERATE_REPORT", f"Zpr√°va '{report_title}' vygenerov√°na do: {report_filename}")
        return f"Zpr√°va '{report_title}' byla √∫spƒõ≈°nƒõ vygenerov√°na do souboru {report_filename}."
    except Exception as e:
        log_activity_tool("Error", "GENERATE_REPORT", f"Chyba p≈ôi generov√°n√≠ zpr√°vy '{report_title}': {e}")
        return f"Chyba p≈ôi generov√°n√≠ zpr√°vy '{report_title}': {e}"

def archive_project_state_tool(description: str) -> str:
    # ... (stejn√© jako p≈ôedt√≠m)
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    archive_name = f"project_state_{timestamp}_{description.replace(' ', '_')}.zip"
    archive_path = os.path.join(ARCHIVE_DIR, archive_name)
    try:
        with zipfile.ZipFile(archive_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for root, _, files in os.walk(PROJECT_ROOT):
                for file in files:
                    file_path = os.path.join(root, file)
                    arcname = os.path.relpath(file_path, PROJECT_ROOT)
                    zipf.write(file_path, arcname)
        log_activity_tool("Archiving", "ARCHIVE_PROJECT_STATE", f"Projekt archivov√°n do: {archive_name}")
        return f"Projekt byl √∫spƒõ≈°nƒõ archivov√°n do {archive_name}."
    except Exception as e:
        log_activity_tool("Error", "ARCHIVE_PROJECT_STATE", f"Chyba p≈ôi archivaci projektu: {e}")
        return f"Chyba p≈ôi archivaci projektu: {e}"

# --- NOV√â N√°stroje pro WebUI a Multimedi√°ln√≠ Vstupy ---

def text_to_speech_tool(text: str) -> str:
    """
    N√°stroj: P≈ôev√°d√≠ text na ≈ôeƒç pomoc√≠ Google Cloud Text-to-Speech API.
    Vrac√≠ base64 k√≥dovan√Ω audio soubor (nebo URL, pokud se ukl√°d√°).
    """
    if not tts_output_enabled:
        return "TTS v√Ωstup je moment√°lnƒõ vypnut."

    synthesis_input = texttospeech.SynthesisInput(text=text)
    voice = texttospeech.VoiceSelectionParams(
        language_code="cs-CZ", # Pou≈æ√≠t ƒçesk√Ω jazyk
        ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL # Nebo FEMALE/MALE
    )
    audio_config = texttospeech.AudioConfig(
        audio_encoding=texttospeech.AudioEncoding.MP3 # MP3 je vhodn√Ω pro web
    )

    try:
        response = tts_client.synthesize_speech(
            input=synthesis_input, voice=voice, audio_config=audio_config
        )
        # Vr√°t√≠me base64 k√≥dovan√Ω ≈ôetƒõzec audio obsahu, kter√Ω pak Frontend p≈ôehraje
        audio_base64 = response.audio_content.hex() # P≈ôevede bin√°rn√≠ data na hex string
        log_activity_tool("Audio Output", "TEXT_TO_SPEECH", f"Text p≈ôeveden na ≈ôeƒç (prvn√≠ch 50 znak≈Ø): {text[:50]}")
        return f"AUDIO_BASE64:{audio_base64}" # Speci√°ln√≠ prefix pro frontend
    except Exception as e:
        log_activity_tool("Error", "TEXT_TO_SPEECH", f"Chyba p≈ôi p≈ôevodu textu na ≈ôeƒç: {e}")
        return f"Chyba p≈ôi p≈ôevodu textu na ≈ôeƒç: {e}"

def speech_to_text_tool(audio_base64: str, language_code: str = "cs-CZ") -> str:
    """
    N√°stroj: P≈ôev√°d√≠ ≈ôeƒç na text pomoc√≠ Google Cloud Speech-to-Text API.
    Oƒçek√°v√° base64 k√≥dovan√Ω audio soubor.
    """
    try:
        audio_content = bytes.fromhex(audio_base64) # Z hex stringu zpƒõt na bytes
        audio = speech.RecognitionAudio(content=audio_content)
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.WEBM_OPUS, # Nebo jin√Ω form√°t, kter√Ω frontend pos√≠l√°
            sample_rate_hertz=48000, # D≈Øle≈æit√©: Nastavte podle nahr√°vky z frontendu
            language_code=language_code,
        )

        response = stt_client.recognize(config=config, audio=audio)
        if response.results:
            transcript = response.results[0].alternatives[0].transcript
            log_activity_tool("Audio Input", "SPEECH_TO_TEXT", f"≈òeƒç p≈ôevedena na text: {transcript[:100]}")
            return transcript
        else:
            log_activity_tool("Audio Input", "SPEECH_TO_TEXT", "Nerozpozn√°na ≈æ√°dn√° ≈ôeƒç.")
            return "Nerozpozn√°na ≈æ√°dn√° ≈ôeƒç."
    except Exception as e:
        log_activity_tool("Error", "SPEECH_TO_TEXT", f"Chyba p≈ôi p≈ôevodu ≈ôeƒçi na text: {e}")
        return f"Chyba p≈ôi p≈ôevodu ≈ôeƒçi na text: {e}"

def analyze_image_tool(image_base64: str, features: list[str] = ["LABEL_DETECTION"]) -> str:
    """
    N√°stroj: Analyzuje obr√°zek pomoc√≠ Google Cloud Vision API nebo Gemini Vision modelu.
    Oƒçek√°v√° base64 k√≥dovan√Ω obr√°zek.
    """
    try:
        image_content = bytes.fromhex(image_base64) # Z hex stringu zpƒõt na bytes
        image = vision.Image(content=image_content)
        
        # M≈Ø≈æete dynamicky p≈ôid√°vat funkce podle po≈æadavk≈Ø AI
        feature_objects = []
        if "LABEL_DETECTION" in features:
            feature_objects.append(vision.Feature(type_=vision.Feature.Type.LABEL_DETECTION))
        if "TEXT_DETECTION" in features:
            feature_objects.append(vision.Feature(type_=vision.Feature.Type.TEXT_DETECTION))
        if "FACE_DETECTION" in features:
            feature_objects.append(vision.Feature(type_=vision.Feature.Type.FACE_DETECTION))

        response = vision_client.annotate_image(image=image, features=feature_objects)
        
        results = []
        if response.label_annotations:
            results.append("Popisky: " + ", ".join([label.description for label in response.label_annotations]))
        if response.full_text_annotation:
            results.append("Rozpoznan√Ω text: " + response.full_text_annotation.text)
        # Dal≈°√≠ anal√Ωzy...
        
        if results:
            log_activity_tool("Image Analysis", "ANALYZE_IMAGE", f"Obr√°zek analyzov√°n. V√Ωsledek: {results[0][:100]}")
            return "\n".join(results)
        else:
            log_activity_tool("Image Analysis", "ANALYZE_IMAGE", "Na obr√°zku nebylo nic relevantn√≠ho rozpozn√°no.")
            return "Na obr√°zku nebylo nic relevantn√≠ho rozpozn√°no."
    except Exception as e:
        log_activity_tool("Error", "ANALYZE_IMAGE", f"Chyba p≈ôi anal√Ωze obr√°zku: {e}")
        return f"Chyba p≈ôi anal√Ωze obr√°zku: {e}"

# Pozn√°mka: `browse_web_tool` je zde zjednodu≈°en√° simulace.
# Pro skuteƒçnou interakci s prohl√≠≈æeƒçem byste pou≈æili Selenium/Playwright.
# Tyto knihovny vy≈æaduj√≠ spu≈°tƒõn√≠ prohl√≠≈æeƒçe, co≈æ je slo≈æitƒõj≈°√≠ v r√°mci serveru.
def browse_web_tool(url: str, selector: str = None) -> str:
    """
    N√°stroj: Nav≈°t√≠v√≠ URL a (volitelnƒõ) extrahuje text pomoc√≠ CSS selektoru.
    Vy≈æaduje Selenium/Playwright a ovladaƒç prohl√≠≈æeƒçe.
    """
    log_activity_tool("Web Access", "BROWSE_WEB", f"Proch√°z√≠m web: {url} se selektorem: {selector}")
    
    # --- SIMULACE ---
    # Toto je placeholder. V re√°ln√©m svƒõtƒõ by zde byl k√≥d Selenium/Playwright
    # Service = ChromeService(ChromeDriverManager().install())
    # driver = webdriver.Chrome(service=Service)
    # try:
    #     driver.get(url)
    #     if selector:
    #         element = driver.find_element(By.CSS_SELECTOR, selector)
    #         content = element.text
    #     else:
    #         content = driver.find_element(By.TAG_NAME, 'body').text # Cel√Ω text
    #     return f"Obsah z {url}:\n{content[:500]}..." # Zkr√°cen√Ω v√Ωstup
    # except Exception as e:
    #     return f"Chyba p≈ôi proch√°zen√≠ {url}: {e}"
    # finally:
    #     driver.quit()
    # --- KONEC SIMULACE ---

    return f"Simulovan√© prohl√≠≈æen√≠ webu pro URL: {url}. Pokud bych mƒõl prohl√≠≈æeƒç, mohl bych teƒè extrahovat data z '{selector}'."

# --- Regex pro robustnƒõj≈°√≠ parsov√°n√≠ tool akc√≠ ---
TOOL_ACTION_PATTERN = re.compile(r'TOOL_ACTION\("([^"]+)"(?:,\s*"(.*?)")?(?:,\s*"(.*?)")?(?:,\s*"(.*?)")?(?:,\s*"(.*?)")?\)')

def parse_tool_action(line: str):
    """Parsuje ≈ô√°dek a extrahuje n√°zev n√°stroje a jeho argumenty."""
    match = TOOL_ACTION_PATTERN.match(line.strip())
    if match:
        tool_name = match.group(1)
        args = [arg for arg in match.groups()[1:] if arg is not None]
        
        # Speci√°ln√≠ o≈°et≈ôen√≠ pro argument 'code_content' a dal≈°√≠ s escapovan√Ωmi znaky
        if tool_name == "WRITE_CODE" and len(args) >= 2:
            args[1] = args[1].replace('\\n', '\n').replace('\\t', '\t').replace('\\"', '"').replace('\\\\', '\\')
        # Dal≈°√≠ dek√≥dov√°n√≠, pokud by jin√© n√°stroje vracely base64 nebo hex.
        if tool_name == "TEXT_TO_SPEECH" and args:
            # Pokud byste pos√≠lali text s uvozovkami, je t≈ôeba je zru≈°it
            args[0] = args[0].replace('\\"', '"')
        
        return tool_name, args
    return None, None

# --- Orchestr√°tor Agenta (Refaktorov√°no jako funkce pro vol√°n√≠ z Flasku) ---
def get_ai_chat_session(session_id):
    """Z√≠sk√°v√° nebo vytv√°≈ô√≠ chatovac√≠ relaci pro danou session_id."""
    if session_id not in user_chats:
        system_instruction = f"""
        Jsi AI Python V√Ωvoj√°≈ô a Mana≈æer Projektu s pokroƒçil√Ωmi komunikaƒçn√≠mi schopnostmi. Tv√Ωm c√≠lem je pom√°hat u≈æivatel≈Øm vyv√≠jet lok√°ln√≠ Python aplikaci, ≈ô√≠dit se v√Ωvojov√Ωm pl√°nem v souboru `{DEVELOPMENT_PLAN_FILE}`, spravovat k√≥d, prov√°dƒõt testy a v√©st z√°znamy. V≈°echny cesty k soubor≈Øm a adres√°≈ô≈Øm se vztahuj√≠ k va≈°emu pracovn√≠mu adres√°≈ôi, tj. `{PROJECT_ROOT}/`.
        
        **Komunikace s u≈æivatelem:**
        -   Bude≈° komunikovat jak se zku≈°en√Ωmi program√°tory (90% ƒçasu), tak s laiky bez znalosti programov√°n√≠ (10% ƒçasu).
        -   **Kl√≠ƒçov√© je rozpoznat styl komunikace u≈æivatele a p≈ôizp≈Øsobit se.**
        -   **Pokud je u≈æivatel profesion√°l:** Pou≈æ√≠vej p≈ôesn√Ω, technick√Ω jazyk. Nab√≠zej konkr√©tn√≠ ≈ôe≈°en√≠ a technick√© detaily. Oƒçek√°vej technick√© zad√°n√≠.
        -   **Pokud je u≈æivatel laik (rozpozn√°≈° ho podle obecn√Ωch, netechnick√Ωch popis≈Ø):**
            -   **Pou≈æ√≠vej jednoduch√Ω, srozumiteln√Ω jazyk.** Vysvƒõtluj slo≈æit√© pojmy srozumiteln√Ωmi srovn√°n√≠mi a **vyhni se program√°torsk√©mu ≈æargonu.**
            -   **Dopt√°vej se postupnƒõ, krok za krokem,** aby jsi p≈ôetavil laick√Ω po≈æadavek na technicky provediteln√© kroky.
            -   **Upozor≈àuj, proƒç se na nƒõco pt√°≈°.** Nap≈ô√≠klad: "Abych mohl p≈ôidat hudbu, pot≈ôebuji vƒõdƒõt, kde je soubor s hudbou ulo≈æen."
            -   **Rozdƒõl komplexn√≠ laick√© √∫koly na men≈°√≠, straviteln√© ot√°zky.**
            -   V≈ædy se sna≈æ p≈ôev√©st my≈°lenku laika do technick√©ho ≈ôe≈°en√≠.

        **Dostupn√© n√°stroje a jejich pou≈æit√≠ (Nov√© a Roz≈°√≠≈ôen√©!):**
        1.  `READ_FILE("filepath")`: P≈ôeƒçte obsah souboru.
        2.  `LIST_DIR("path")`: Vyp√≠≈°e obsah adres√°≈ôe.
        3.  `WRITE_CODE("filename", "code_content")`: Zap√≠≈°e Python k√≥d do souboru. (Nezapome≈à escapovat `\\n`, `\\"` atd.)
        4.  `TEST_CODE("filename")`: Spust√≠ Python soubor jako test.
        5.  `GENERATE_TEST_BOILERPLATE("target_filename", "function_names_comma_separated")`: Generuje z√°kladn√≠ strukturu pro unit testy.
        6.  `LOG_ACTIVITY("category", "action", "details")`: Zaznamen√° aktivitu.
        7.  `GENERATE_REPORT("report_title")`: Vytvo≈ô√≠ souhrnnou zpr√°vu.
        8.  `ARCHIVE_PROJECT_STATE("description")`: Vytvo≈ô√≠ zip archiv aktu√°ln√≠ho stavu.
        9.  `TEXT_TO_SPEECH("text_to_speak")`: P≈ôev√°d√≠ text na mluvenou ≈ôeƒç, kterou m≈Ø≈æe u≈æivatel sly≈°et. Pou≈æij, pokud je aktivov√°n hlasov√Ω v√Ωstup.
        10. `SPEECH_TO_TEXT("audio_base64", "language_code")`: P≈ôev√°d√≠ audio vstup od u≈æivatele (kter√Ω p≈ôij√≠m√°≈° od orchestr√°tora) na text. **Tento n√°stroj vol√° orchestr√°tor, ne ty.**
        11. `ANALYZE_IMAGE("image_base64", "features_comma_separated")`: Analyzuje obr√°zek (kter√Ω p≈ôij√≠m√°≈° od orchestr√°tora) a vr√°t√≠ popisky, text nebo dal≈°√≠ informace.
        12. `BROWSE_WEB("url", "optional_css_selector")`: Nav≈°t√≠v√≠ URL a m≈Ø≈æe extrahovat obsah pomoc√≠ CSS selektoru. Pou≈æij pro vyhled√°v√°n√≠ informac√≠ nebo anal√Ωzu webov√Ωch str√°nek.

        **Z√°sady pr√°ce:**
        -   P≈ôi ka≈æd√© v√Ωznamn√© akci pou≈æij `LOG_ACTIVITY`.
        -   Po generov√°n√≠ k√≥du a test≈Ø pou≈æij `WRITE_CODE` a `TEST_CODE`.
        -   Pravidelnƒõ generuj zpr√°vy (`GENERATE_REPORT`) a archivuj stav (`ARCHIVE_PROJECT_STATE`).
        -   **V≈ædy informuj u≈æivatele o tom, co dƒõl√°≈°, o v√Ωsledc√≠ch n√°stroj≈Ø a o sv√©m dal≈°√≠m pl√°nu.**
        -   **Pou≈æ√≠vej n√°stroj `TEXT_TO_SPEECH` POUZE pokud je hlasov√Ω v√Ωstup aktivov√°n, jinak komunikuj textem.** Informaci o aktivaci ti p≈ôed√° orchestr√°tor v kontextu.
        -   Python k√≥d generuj v markdown bloc√≠ch (```python ... ```).
        -   Pokud u≈æivatel po≈°le obr√°zek nebo hlas, bude ti to sdƒõleno. Analyzuj je pomoc√≠ `ANALYZE_IMAGE` nebo `SPEECH_TO_TEXT` (kter√Ω vol√° orchestr√°tor) a zahr≈à v√Ωsledek do sv√© √∫vahy.
        -   Pou≈æ√≠vej `BROWSE_WEB` k z√≠sk√°n√≠ informac√≠, kter√© pot≈ôebuje≈° k ≈ôe≈°en√≠ √∫kol≈Ø.
        """
        user_chats[session_id] = code_model.start_chat(history=[
            {"role": "user", "parts": [system_instruction]},
            {"role": "model", "parts": ["Ok, rozum√≠m sv√© roli a n√°stroj≈Øm, kter√© mohu pou≈æ√≠vat. Jsem p≈ôipraven ≈ô√≠dit v√Ωvoj projektu. Jak v√°m dnes mohu pomoci? Pros√≠m, popi≈°te mi sv≈Øj √∫kol co nejl√©pe, abychom mohli zaƒç√≠t. Pokud nejste program√°tor, klidnƒõ mi to popi≈°te sv√Ωmi slovy, pokus√≠m se tomu porozumƒõt a doptat se!"]}
        ])
    return user_chats[session_id]

def process_ai_response(session_id, gemini_output: str):
    """
    Zpracuje v√Ωstup z Gemini modelu, provede vol√°n√≠ n√°stroj≈Ø a ode≈°le v√Ωsledky zpƒõt.
    """
    global tts_output_enabled # P≈ô√≠stup ke glob√°ln√≠ promƒõnn√©

    chat = get_ai_chat_session(session_id)
    emitted_messages = [] # Seznam zpr√°v, kter√© se maj√≠ poslat frontendu

    # Zpracov√°n√≠ textov√©ho v√Ωstupu od AI
    emitted_messages.append({"type": "text", "content": gemini_output})
    
    # Pokud je TTS aktivn√≠, pokus√≠me se p≈ôev√©st text na ≈ôeƒç
    if tts_output_enabled:
        # Odstran√≠ TOOL_ACTION z mluven√©ho v√Ωstupu
        speech_text = re.sub(r'TOOL_ACTION\(.*?\)', '', gemini_output).strip()
        if speech_text:
            tts_result = text_to_speech_tool(speech_text)
            if tts_result.startswith("AUDIO_BASE64:"):
                audio_data_base64 = tts_result.split(":", 1)[1]
                emitted_messages.append({"type": "audio", "content": audio_data_base64})
            else:
                emitted_messages.append({"type": "error", "content": f"Chyba TTS: {tts_result}"})

    # Analyzujte odpovƒõƒè Gemini pro akce n√°stroj≈Ø
    lines = gemini_output.split('\n')
    for line in lines:
        tool_name, args = parse_tool_action(line)
        
        if tool_name:
            tool_result = "Nezn√°m√Ω n√°stroj nebo chyba p≈ôi spu≈°tƒõn√≠."
            
            # Mapov√°n√≠ n√°stroj≈Ø na Python funkce
            tool_map = {
                "READ_FILE": read_file_tool,
                "LIST_DIR": list_directory_tool,
                "WRITE_CODE": write_code_to_file_tool,
                "TEST_CODE": test_python_code_tool,
                "GENERATE_TEST_BOILERPLATE": generate_test_boilerplate_tool,
                "LOG_ACTIVITY": log_activity_tool,
                "GENERATE_REPORT": generate_report_tool,
                "ARCHIVE_PROJECT_STATE": archive_project_state_tool,
                "TEXT_TO_SPEECH": text_to_speech_tool, # Tato se vol√° shora, ne zde
                "SPEECH_TO_TEXT": speech_to_text_tool, # Tato se vol√° z frontendu
                "ANALYZE_IMAGE": analyze_image_tool, # Tato se vol√° z frontendu
                "BROWSE_WEB": browse_web_tool
            }

            if tool_name in tool_map:
                try:
                    tool_result = tool_map[tool_name](*args)
                except TypeError as te:
                    tool_result = f"Chyba vol√°n√≠ n√°stroje '{tool_name}': Nespr√°vn√Ω poƒçet/typ argument≈Ø. Chyba: {te}"
                    log_activity_tool("Error", "TOOL_CALL", tool_result)
                except Exception as e:
                    tool_result = f"N√°stroj '{tool_name}' selhal: {e}\n{traceback.format_exc()}"
                    log_activity_tool("Error", "TOOL_CALL", tool_result)
            else:
                tool_result = f"Nezn√°m√Ω n√°stroj: {tool_name}"
                log_activity_tool("Error", "TOOL_CALL", tool_result)
            
            # Ode≈°leme v√Ωsledek n√°stroje zpƒõt modelu Gemini pro kontext
            chat.send_message(f"N√°stroj '{tool_name}' dokonƒçen. V√Ωsledek: {tool_result}")
            emitted_messages.append({"type": "tool_output", "tool": tool_name, "result": tool_result})
            
            # Pokud je live mode aktivn√≠, po≈°leme prompt k pokraƒçov√°n√≠
            if live_mode_enabled:
                socketio.sleep(0.1) # Mal√° pauza, aby se frontend stihl aktualizovat
                continue_ai_processing(session_id) # Automaticky pokraƒçuj

    for msg in emitted_messages:
        socketio.emit('ai_response', msg, room=session_id)

def continue_ai_processing(session_id):
    """Pokraƒçuje v zpracov√°n√≠ AI v live re≈æimu."""
    chat = get_ai_chat_session(session_id)
    try:
        response = chat.send_message("Pokraƒçuj v pr√°ci na projektu a generuj dal≈°√≠ akce nebo k√≥d podle pl√°nu a aktu√°ln√≠ho stavu.")
        process_ai_response(session_id, response.text)
    except Exception as e:
        error_msg = f"Chyba p≈ôi pokraƒçov√°n√≠ AI: {e}\n{traceback.format_exc()}"
        socketio.emit('ai_response', {"type": "error", "content": error_msg}, room=session_id)
        log_activity_tool("Error", "LIVE_MODE", error_msg)

# --- Flask Routes a SocketIO Event Handlers ---

@app.route('/')
def index():
    return render_template('index.html')

@socketio.on('connect')
def handle_connect():
    session_id = request.sid
    user_chats[session_id] = get_ai_chat_session(session_id) # Zajist√≠ session pro nov√©ho u≈æivatele
    print(f"Klient p≈ôipojen, SID: {session_id}")
    emit('ai_response', {"type": "info", "content": "V√≠tejte! Jsem AI Mana≈æer V√Ωvoje Aplikac√≠. Jak v√°m dnes mohu pomoci?"})
    # Po≈°le poƒç√°teƒçn√≠ zpr√°vu od AI po nav√°z√°n√≠ spojen√≠
    # chat = user_chats[session_id]
    # initial_message = chat.history[1].parts[0].text # Z√≠skej √∫vodn√≠ zpr√°vu z historie
    # process_ai_response(session_id, initial_message) # Ode≈°li ji klientovi


@socketio.on('disconnect')
def handle_disconnect():
    session_id = request.sid
    if session_id in user_chats:
        del user_chats[session_id] # Vyƒçist√≠ chat session
    print(f"Klient odpojen, SID: {session_id}")

@socketio.on('send_message')
def handle_send_message(data):
    session_id = request.sid
    user_message = data['message']
    
    chat = get_ai_chat_session(session_id)
    
    emit('user_message', {"content": user_message}) # Zobraz√≠ zpr√°vu u≈æivatele ve UI

    try:
        # Ode≈°li u≈æivatelskou zpr√°vu AI a z√≠skej odpovƒõƒè
        response = chat.send_message(user_message)
        process_ai_response(session_id, response.text)
    except Exception as e:
        error_msg = f"Chyba p≈ôi komunikaci s AI: {e}\n{traceback.format_exc()}"
        emit('ai_response', {"type": "error", "content": error_msg})
        log_activity_tool("Error", "CHAT_MESSAGE", error_msg)

@socketio.on('send_audio')
def handle_send_audio(data):
    session_id = request.sid
    audio_base64 = data['audio_data']
    
    # Pou≈æijte n√°stroj SPEECH_TO_TEXT k p≈ôevodu audio na text
    transcript = speech_to_text_tool(audio_base64)
    emit('ai_response', {"type": "info", "content": f"Rozpoznan√Ω text: {transcript}"})
    
    if transcript and not transcript.startswith("Chyba:") and not transcript.startswith("Nerozpozn√°na"):
        # Pokud bylo audio √∫spƒõ≈°nƒõ p≈ôevedeno na text, po≈°lete text AI
        handle_send_message({"message": transcript})
    else:
        emit('ai_response', {"type": "info", "content": "Pros√≠m, zkuste to znovu s ƒçistƒõj≈°√≠m hlasem."})

@socketio.on('send_image')
def handle_send_image(data):
    session_id = request.sid
    image_base64 = data['image_data']
    
    # Pou≈æijte n√°stroj ANALYZE_IMAGE k anal√Ωze obr√°zku
    analysis_result = analyze_image_tool(image_base64, features=["LABEL_DETECTION", "TEXT_DETECTION"])
    emit('ai_response', {"type": "info", "content": f"V√Ωsledek anal√Ωzy obr√°zku: {analysis_result}"})
    
    # Po≈°lete v√Ωsledek anal√Ωzy AI
    handle_send_message({"message": f"U≈æivatel mi poslal obr√°zek s anal√Ωzou: {analysis_result}. M≈Ø≈æe≈° to vyu≈æ√≠t."})

@socketio.on('toggle_tts')
def handle_toggle_tts(data):
    global tts_output_enabled
    tts_output_enabled = data['enabled']
    status = "zapnut" if tts_output_enabled else "vypnut"
    emit('ai_response', {"type": "info", "content": f"Hlasov√Ω v√Ωstup AI byl {status}."})
    log_activity_tool("Settings", "TTS_TOGGLE", f"Hlasov√Ω v√Ωstup AI byl {status}.")

@socketio.on('toggle_live_mode')
def handle_toggle_live_mode(data):
    global live_mode_enabled
    live_mode_enabled = data['enabled']
    status = "zapnut" if live_mode_enabled else "vypnut"
    emit('ai_response', {"type": "info", "content": f"≈Ωiv√Ω re≈æim byl {status}."})
    log_activity_tool("Settings", "LIVE_MODE_TOGGLE", f"≈Ωiv√Ω re≈æim byl {status}.")
    
    if live_mode_enabled:
        # Pokud byl live mode zapnut, okam≈æitƒõ po≈æ√°dej AI o pokraƒçov√°n√≠
        continue_ai_processing(request.sid)

# --- Spu≈°tƒõn√≠ Flask aplikace ---
if __name__ == '__main__':
    print(f"Spou≈°t√≠m Flask aplikaci. Otev≈ôete http://127.0.0.1:5000 ve va≈°em prohl√≠≈æeƒçi.")
    socketio.run(app, debug=True, allow_unsafe_werkzeug=True) # debug=True pro development
```

---

### **Koncept Frontend (HTML/JavaScript) ‚Äì Soubor `templates/index.html`:**

Tento soubor by mƒõl b√Ωt um√≠stƒõn v adres√°≈ôi `templates/`. Bude slou≈æit jako rozhran√≠ pro u≈æivatele.

```html
<!DOCTYPE html>
<html lang="cs">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Developer Manager</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.0.0/socket.io.js"></script>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; background-color: #f4f4f4; color: #333; }
        .chat-container { max-width: 800px; margin: 0 auto; background-color: #fff; padding: 20px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); display: flex; flex-direction: column; min-height: 70vh; }
        .messages { flex-grow: 1; border: 1px solid #ddd; padding: 15px; margin-bottom: 15px; border-radius: 4px; overflow-y: scroll; max-height: 50vh; background-color: #e9e9e9; }
        .message-box { display: flex; margin-bottom: 10px; }
        .message-box.user { justify-content: flex-end; }
        .message-box.ai { justify-content: flex-start; }
        .message { padding: 8px 12px; border-radius: 18px; max-width: 70%; line-height: 1.4; }
        .message.user { background-color: #007bff; color: white; border-bottom-right-radius: 2px; }
        .message.ai { background-color: #e0e0e0; color: #333; border-bottom-left-radius: 2px; }
        .input-area { display: flex; gap: 10px; margin-top: 15px; }
        .input-area input[type="text"] { flex-grow: 1; padding: 10px; border: 1px solid #ddd; border-radius: 4px; }
        .input-area button { padding: 10px 15px; background-color: #28a745; color: white; border: none; border-radius: 4px; cursor: pointer; }
        .input-area button:hover { background-color: #218838; }
        .controls { display: flex; justify-content: space-around; margin-top: 20px; padding-top: 15px; border-top: 1px solid #eee; }
        .controls button, .controls label { padding: 8px 12px; border: 1px solid #ccc; border-radius: 4px; background-color: #f0f0f0; cursor: pointer; }
        .controls button:hover, .controls label:hover { background-color: #e0e0e0; }
        .log-display { margin-top: 20px; border: 1px solid #ddd; padding: 10px; background-color: #f9f9f9; max-height: 200px; overflow-y: scroll; font-size: 0.8em; white-space: pre-wrap; word-break: break-all; }
        .hidden { display: none; }
    </style>
</head>
<body>
    <div class="chat-container">
        <h1>AI Developer Manager</h1>
        <div class="messages" id="messages">
            <!-- Messages will be displayed here -->
        </div>
        <div class="input-area">
            <input type="text" id="user_input" placeholder="Zadejte zpr√°vu...">
            <button id="send_button">Odeslat Zpr√°vu</button>
            <button id="microphone_button">üéôÔ∏è Hlasov√Ω Vstup</button>
            <input type="file" id="image_input" accept="image/*" class="hidden">
            <button id="upload_image_button">üñºÔ∏è Nahr√°t Obr√°zek</button>
        </div>
        <div class="controls">
            <label>
                <input type="checkbox" id="tts_toggle"> Hlasov√Ω V√Ωstup AI
            </label>
            <label>
                <input type="checkbox" id="live_mode_toggle"> ≈Ωiv√Ω Re≈æim
            </label>
        </div>
    </div>

    <script>
        const socket = io();
        const messagesDiv = document.getElementById('messages');
        const userInput = document.getElementById('user_input');
        const sendButton = document.getElementById('send_button');
        const microphoneButton = document.getElementById('microphone_button');
        const ttsToggle = document.getElementById('tts_toggle');
        const liveModeToggle = document.getElementById('live_mode_toggle');
        const imageInput = document.getElementById('image_input');
        const uploadImageButton = document.getElementById('upload_image_button');

        // Funkce pro p≈ôid√°n√≠ zpr√°vy do chatu
        function addMessage(sender, content, type = 'text') {
            const messageBox = document.createElement('div');
            messageBox.classList.add('message-box', sender);
            const message = document.createElement('div');
            message.classList.add('message', sender);
            message.innerText = content;
            messageBox.appendChild(message);
            messagesDiv.appendChild(messageBox);
            messagesDiv.scrollTop = messagesDiv.scrollHeight; // Scroll to bottom
        }

        // --- SocketIO Handlers ---
        socket.on('connect', () => {
            console.log('Connected to server');
        });

        socket.on('ai_response', (data) => {
            if (data.type === 'text' || data.type === 'info' || data.type === 'error' || data.type === 'tool_output') {
                addMessage('ai', data.content);
            } else if (data.type === 'audio') {
                // P≈ôehr√°t audio z base64 dat
                const audio = new Audio(`data:audio/mp3;base64,${data.content}`);
                audio.play().catch(e => console.error("Error playing audio:", e));
                addMessage('ai', 'P≈ôehr√°v√°m zvukovou odpovƒõƒè...');
            }
        });

        socket.on('user_message', (data) => {
            addMessage('user', data.content);
        });

        // --- Event Listeners pro UI prvky ---
        sendButton.addEventListener('click', () => {
            const message = userInput.value;
            if (message.trim()) {
                socket.emit('send_message', { message: message });
                userInput.value = '';
            }
        });

        userInput.addEventListener('keypress', (e) => {
            if (e.key === 'Enter') {
                sendButton.click();
            }
        });

        ttsToggle.addEventListener('change', () => {
            socket.emit('toggle_tts', { enabled: ttsToggle.checked });
        });

        liveModeToggle.addEventListener('change', () => {
            socket.emit('toggle_live_mode', { enabled: liveModeToggle.checked });
        });

        // --- Mikrofonn√≠ Vstup (Speech-to-Text) ---
        let mediaRecorder;
        let audioChunks = [];

        microphoneButton.addEventListener('click', async () => {
            if (microphoneButton.classList.contains('recording')) {
                // Zastavit nahr√°v√°n√≠
                mediaRecorder.stop();
                microphoneButton.classList.remove('recording');
                microphoneButton.innerText = 'üéôÔ∏è Hlasov√Ω Vstup';
            } else {
                // Spustit nahr√°v√°n√≠
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm;codecs=opus' }); // WebM s Opus je dobr√° volba

                    mediaRecorder.ondataavailable = (event) => {
                        audioChunks.push(event.data);
                    };

                    mediaRecorder.onstop = async () => {
                        const audioBlob = new Blob(audioChunks, { type: 'audio/webm;codecs=opus' });
                        const reader = new FileReader();
                        reader.onloadend = () => {
                            const base64Audio = reader.result.split(',')[1]; // Extrahovat base64 ƒç√°st
                            socket.emit('send_audio', { audio_data: base64Audio });
                        };
                        reader.readAsDataURL(audioBlob);
                        audioChunks = []; // Vyƒçistit pro dal≈°√≠ nahr√°v√°n√≠
                    };

                    mediaRecorder.start();
                    microphoneButton.classList.add('recording');
                    microphoneButton.innerText = 'üî¥ Nahr√°v√°m...';
                    addMessage('user', 'Nahr√°v√°m hlasov√Ω vstup...');
                } catch (err) {
                    console.error('Chyba p≈ôi p≈ô√≠stupu k mikrofonu:', err);
                    addMessage('ai', 'Chyba p≈ôi p≈ô√≠stupu k mikrofonu. Ujistƒõte se, ≈æe m√°te povolen p≈ô√≠stup.');
                }
            }
        });

        // --- Nahr√°v√°n√≠ Obr√°zk≈Ø ---
        uploadImageButton.addEventListener('click', () => {
            imageInput.click(); // Spust√≠ dialog pro v√Ωbƒõr souboru
        });

        imageInput.addEventListener('change', (event) => {
            const file = event.target.files[0];
            if (file) {
                const reader = new FileReader();
                reader.onloadend = () => {
                    const base64Image = reader.result.split(',')[1]; // Extrahovat base64 ƒç√°st
                    socket.emit('send_image', { image_data: base64Image });
                    addMessage('user', 'Obr√°zek nahr√°n k anal√Ωze.');
                };
                reader.readAsDataURL(file);
            }
        });

        // Po prvn√≠m naƒçten√≠ str√°nky iniciovat AI
        // Toto bude odesl√°no po p≈ôipojen√≠ klienta k serveru.
        // M≈Ø≈æete zv√°≈æit posl√°n√≠ inicializaƒçn√≠ zpr√°vy od serveru, jak je ji≈æ nastaveno v socket.on('connect')
    </script>
</body>
</html>
```

---

### **Vysvƒõtlen√≠ architektury a budouc√≠ch krok≈Ø:**

1.  **`app.py` (Backend):**
    *   **Flask & SocketIO:** Toto je v√°≈° webov√Ω server. `Flask` obsluhuje HTML str√°nku, `SocketIO` vytv√°≈ô√≠ WebSocket spojen√≠ pro real-time komunikaci (pro chat, hlas, ≈æiv√Ω re≈æim).
    *   **Google Cloud SDKs:** Integrace s `google-cloud-texttospeech`, `google-cloud-speech`, `google-cloud-vision` je p≈ôipravena. Budete pot≈ôebovat aktivovat tyto API ve va≈°em Google Cloud projektu a nastavit autentifikaci (ide√°lnƒõ p≈ôes promƒõnnou prost≈ôed√≠ `GOOGLE_APPLICATION_CREDENTIALS`).
    *   **Nov√© n√°stroje v AI pro komunikaci:**
        *   `TEXT_TO_SPEECH("text")`: AI m≈Ø≈æe explicitnƒõ po≈æadovat, aby se urƒçit√Ω text p≈ôevedl na ≈ôeƒç. Pokud je TTS v UI zapnut√©, backend to provede.
        *   `SPEECH_TO_TEXT("audio_base64", "language_code")`: Tento n√°stroj *nen√≠ vol√°n AI*. Je vol√°n Python backendem, kdy≈æ p≈ôijme zvuk z frontendu. AI je pak informov√°na o jeho v√Ωsledku.
        *   `ANALYZE_IMAGE("image_base64", "features")`: Podobnƒõ, AI tento n√°stroj nevol√° p≈ô√≠mo. Backend ho vol√°, kdy≈æ u≈æivatel nahraje obr√°zek, a AI je informov√°na o v√Ωsledku.
        *   `BROWSE_WEB("url", "selector")`: Toto je placeholder pro integraci se Selenium/Playwright. Tato ƒç√°st by vy≈æadovala spu≈°tƒõn√≠ headless prohl√≠≈æeƒçe na serveru, co≈æ je n√°roƒçn√© na zdroje a konfiguraci.
    *   **Glob√°ln√≠ stav (`live_mode_enabled`, `tts_output_enabled`):** Pro jednoduchost demo jsou tyto glob√°ln√≠. V produkƒçn√≠m prost≈ôed√≠ byste je spravovali per-session (nap≈ô. v `session` objektu Flasku nebo v datab√°zi), aby ka≈æd√Ω u≈æivatel mƒõl sv√© nastaven√≠.
    *   **`process_ai_response`:** Tato funkce je kl√≠ƒçov√°. Zpracov√°v√° odpovƒõƒè AI, vol√° n√°stroje, p≈ô√≠padnƒõ prov√°d√≠ TTS a emituje v√Ωsledky zpƒõt frontendu.
    *   **`@socketio.on(...)`:** Tyto dekor√°tory definuj√≠, co se stane, kdy≈æ frontend po≈°le specifickou zpr√°vu (nap≈ô. 'send_message', 'send_audio', 'toggle_tts').

2.  **`templates/index.html` (Frontend):**
    *   **HTML:** Z√°kladn√≠ struktura pro chatovac√≠ rozhran√≠, vstupy a ovl√°dac√≠ prvky.
    *   **CSS:** Jednoduch√Ω styling.
    *   **JavaScript:**
        *   **Socket.IO Client:** Navazuje a udr≈æuje spojen√≠ s Flask backendem.
        *   **`addMessage()`:** Pomocn√° funkce pro p≈ôid√°v√°n√≠ zpr√°v do UI.
        *   **Mikrofon (Web Speech API):** Pou≈æ√≠v√° `navigator.mediaDevices.getUserMedia` k nahr√°v√°n√≠ zvuku z mikrofonu. Nahr√°v√° se jako `audio/webm;codecs=opus` (dobr√Ω form√°t pro web). Zvuk je pak zak√≥dov√°n do Base64 a posl√°n p≈ôes WebSocket na backend.
        *   **P≈ôehr√°v√°n√≠ TTS:** Kdy≈æ backend po≈°le data typu `audio` (base64 k√≥dovan√Ω MP3), JavaScript vytvo≈ô√≠ `Audio` objekt a p≈ôehraje ho.
        *   **Nahr√°v√°n√≠ obr√°zk≈Ø:** ƒåte soubor obr√°zku a pos√≠l√° ho jako Base64 na backend.
        *   **P≈ôep√≠naƒçe:** Jednoduch√© listenery pro p≈ôep√≠n√°n√≠ TTS a ≈æiv√©ho re≈æimu, pos√≠laj√≠c√≠ stav na backend.

### **Integrace Selektor≈Ø a Anal√Ωza Log≈Ø (Specifick√© body):**

*   **Nastavov√°n√≠ Selektor≈Ø pro Anal√Ωzu Log≈Ø:** V `system_instruction` je novƒõ n√°stroj `BROWSE_WEB("url", "optional_css_selector")`. AI m≈Ø≈æe (po≈æ√°d√°no nebo z vlastn√≠ iniciativy) ≈ô√≠ct: `TOOL_ACTION("BROWSE_WEB", "https://example.com/logs", "div.log-entry p.timestamp")`. Python backend by pak (s funkƒçn√≠ implementac√≠ Selenium/Playwright) nav≈°t√≠vil URL a extrahoval by text z prvk≈Ø odpov√≠daj√≠c√≠ch selektoru. Tento extrahovan√Ω text by byl vr√°cen AI k anal√Ωze.
*   **Anal√Ωza Log≈Ø AI:** Jakmile AI obdr≈æ√≠ text z log≈Ø (nap≈ô. z n√°stroje `READ_FILE` nebo `BROWSE_WEB`), jej√≠ generativn√≠ schopnosti j√≠ umo≈æn√≠:
    *   Rozpoznat vzory v datech.
    *   Identifikovat chyby nebo upozornƒõn√≠.
    *   Souhrnnƒõ popsat ud√°losti.
    *   Navrhnout ≈ôe≈°en√≠ probl√©m≈Ø na z√°kladƒõ anal√Ωzy log≈Ø.
    *   Tyto anal√Ωzy by byly souƒç√°st√≠ bƒõ≈æn√©ho chatovac√≠ho v√Ωstupu AI a byly by zaznamen√°ny n√°strojem `LOG_ACTIVITY`.

### **Jak to spustit:**

1.  Ujistƒõte se, ≈æe m√°te nainstalovan√© v≈°echny knihovny (`pip install ...`).
2.  Nastavte promƒõnnou prost≈ôed√≠ `GOOGLE_API_KEY` a p≈ô√≠padnƒõ `GOOGLE_APPLICATION_CREDENTIALS` (pro Google Cloud API).
3.  Ujistƒõte se, ≈æe m√°te adres√°≈ôovou strukturu a soubor `development_plan.txt` tak, jak je pops√°no na zaƒç√°tku.
4.  Spus≈•te backend:
    ```bash
    python app.py
    ```
5.  Otev≈ôete webov√Ω prohl√≠≈æeƒç (nap≈ô. Chromium) a p≈ôejdƒõte na `http://127.0.0.1:5000`.

Tento komplexn√≠ syst√©m v√°m poskytne robustn√≠ z√°klad pro interakci s va≈°√≠m AI program√°torem prost≈ôednictv√≠m modern√≠ho webov√©ho rozhran√≠ s bohat√Ωmi mo≈ænostmi vstupu a v√Ωstupu. Vy≈æaduje v≈°ak dal≈°√≠ pr√°ci na frontendu a peƒçlivou spr√°vu API kl√≠ƒç≈Ø a kv√≥t.